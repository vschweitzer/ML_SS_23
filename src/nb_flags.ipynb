{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run preprocess_flags.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, chi2, f_classif, mutual_info_classif\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = normalized_df\n",
    "random_state: int = 0\n",
    "np.random.seed(42)\n",
    "X = df.drop(\"religion\", axis=1)\n",
    "y = df[\"religion\"]\n",
    "religion_encoder = LabelEncoder()\n",
    "religion_encoder.fit(y)\n",
    "y = religion_encoder.transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3)\n",
    "\n",
    "train_countries = X_train[\"name\"]\n",
    "test_countries = X_test[\"name\"]\n",
    "\n",
    "X_train.drop(\"name\", axis=1, inplace=True)\n",
    "X_test.drop(\"name\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector = GenericUnivariateSelect()\n",
    "pipeline = Pipeline(steps=[(\"feature_selector\", feature_selector), (\"classifier\", ComplementNB())])\n",
    "pipelines = {\n",
    "    \"ComplementNB\": pipeline\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 4\n",
    "\n",
    "cross_args = {\n",
    "    \"ComplementNB\": [\n",
    "        {\n",
    "            \"feature_selector__score_func\": [chi2, f_classif],\n",
    "            \"feature_selector__mode\": [\"fpr\", \"fdr\", \"fwe\"],\n",
    "            \"feature_selector__param\": np.arange(0.0, 0.5, 0.025),\n",
    "            \"classifier__alpha\": [\n",
    "                10 ** power for power in np.arange(-10 / freq, 20 / freq, 1 / freq)\n",
    "            ],\n",
    "        }, \n",
    "        {\n",
    "            \"feature_selector__score_func\": [chi2, f_classif, mutual_info_classif],\n",
    "            \"feature_selector__mode\": [\"k_best\"],\n",
    "            \"feature_selector__param\": list(range(5, X_train.shape[1])),\n",
    "            \"classifier__alpha\": [\n",
    "                10 ** power for power in np.arange(-10 / freq, 20 / freq, 1 / freq)\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"min_samples_split\": [2, 4, 8, 16],\n",
    "        \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"ComplementNB\"\n",
    "pipe = pipelines[name]\n",
    "args = cross_args[name]\n",
    "scoring_criterium = \"f1_macro\"\n",
    "\n",
    "search = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=args,\n",
    "    scoring=scoring_criterium,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cl = ComplementNB()\n",
    "test_cl.fit(X_train, y_train)\n",
    "f1_score(y_test, test_cl.predict(X_test), average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipe = pipe.set_params(**search.best_params_)\n",
    "best_pipe.fit(X_train, y_train)\n",
    "f1_score(y_test, best_pipe.predict(X_test), average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_correct = (y_test == best_pipe.predict(X_test)).sum()\n",
    "print(f\"{n_correct} of {X_test.shape[0]} ({n_correct / X_test.shape[0]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_results = pd.DataFrame.from_records(search.cv_results_[\"params\"])\n",
    "cs_results[\"feature_selector__score_func\"] = cs_results[\"feature_selector__score_func\"].apply(lambda x: x.__name__)\n",
    "\n",
    "score_keys = [key for key in search.cv_results_.keys() if str(key).startswith(\"split\")]\n",
    "for score_key in score_keys:\n",
    "    cs_results[score_key] = search.cv_results_[score_key]\n",
    "\n",
    "cs_results[\"score_mean\"] = cs_results[score_keys].mean(axis=1)\n",
    "cs_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/53904155/flexibly-select-pandas-dataframe-rows-using-dictionary\n",
    "best_params_formatted = {}\n",
    "for key in search.best_params_:\n",
    "    if callable(search.best_params_[key]):\n",
    "        best_params_formatted[key] = search.best_params_[key].__name__\n",
    "    else:\n",
    "        best_params_formatted[key] = search.best_params_[key]\n",
    "query = ' and '.join([f'{k} == {repr(v)}' for k, v in best_params_formatted.items()]) \n",
    "\n",
    "best_score = cs_results.query(query)[\"score_mean\"]\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = best_pipe.predict(X_test)\n",
    "true_labels, predicted_labels = religion_encoder.inverse_transform(y_test), religion_encoder.inverse_transform(y_predicted)\n",
    "labels = np.unique(true_labels)\n",
    "cm = confusion_matrix(true_labels, predicted_labels, labels=labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "#cmp = ConfusionMatrixDisplay(cm, display_labels=religion_encoder.classes_, xticks_rotation=\"vertical\")\n",
    "cmp = ConfusionMatrixDisplay.from_estimator(best_pipe, X_test, y_test, display_labels=religion_encoder.classes_[:-1], xticks_rotation=\"vertical\")\n",
    "#cmp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_modes = list(cs_results[\"feature_selector__mode\"].unique())\n",
    "score_functions = list(cs_results[\"feature_selector__score_func\"].unique())\n",
    "cs_heatmaps = []\n",
    "\n",
    "\n",
    "for score_function in score_functions:\n",
    "    for selector_mode in selector_modes:\n",
    "        plt.figure()\n",
    "        cs_heatmaps.append(sns.heatmap(cs_results[(cs_results[\"feature_selector__mode\"] == selector_mode) & (cs_results[\"feature_selector__score_func\"] == score_function)].pivot(index=\"classifier__alpha\", columns=\"feature_selector__param\", values=\"score_mean\"), vmin=0.0, vmax=0.55))\n",
    "        cs_heatmaps[-1].set_xlabel(f\"Mode: {selector_mode} ({score_function})\")\n",
    "        cs_heatmaps[-1].set_ylabel(\"Alpha\")\n",
    "        cs_heatmaps[-1].set_title(f\"Complement Naive Bayes {scoring_criterium} by Selector Parameter and Alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_scores = pd.DataFrame(list(zip(best_pipe[-2].scores_, best_pipe[-2].feature_names_in_)), columns=[\"Score\", \"Name\"]).sort_values(\"Score\", ascending=False)\n",
    "included_features = best_pipe[-2].get_feature_names_out()\n",
    "features_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_fig, scoring_ax = plt.subplots(figsize=(6, 15))\n",
    "sns.barplot(features_scores, y=\"Name\", x=\"Score\", orient=\"horizontal\", width=0.8, dodge=True, ax=scoring_ax)\n",
    "for t in scoring_ax.yaxis.get_ticklabels():\n",
    "    if t.get_text() in included_features:\n",
    "        t.set_color(\"#008800\")\n",
    "scoring_ax.set_title(f\"Feature Importance as determined by {best_pipe[-2].get_params()['score_func'].__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_predicted, target_names=religion_encoder.classes_[:-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
