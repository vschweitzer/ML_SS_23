{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run generic_pipeline.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from FCLayer import FcLayer\n",
    "from ACLayer import AcLayer\n",
    "from Network import Network\n",
    "from GridSearch import GridSearcher\n",
    "from activation_functions import sigmoid, sigmoid_derivative, tanh, tanh_derivative, relu, relu_derivative\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 1000\n",
    "network1 = Network(learning_rate=learning_rate, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.33916615e-04, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.26792251e-01, 1.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.46388715e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [2.89259888e-02, 1.58730159e-02, 0.00000000e+00, ...,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.52664941e-02, 1.98412698e-03, 0.00000000e+00, ...,\n",
       "        1.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# input_values = len(X_train.columns)\n",
    "# output_values = 1\n",
    "# intermediate_values = 3\n",
    "# layers = 3\n",
    "\n",
    "# for j in range(layers):\n",
    "#     i = intermediate_values\n",
    "#     o = intermediate_values\n",
    "\n",
    "#     if not j:\n",
    "#         i = input_values\n",
    "#     elif j + 1 == layers:\n",
    "#         o = output_values\n",
    "\n",
    "#     fc = FcLayer(i, o)\n",
    "#     ac = AcLayer(tanh, tanh_prime)\n",
    "#     network1.add(fc)\n",
    "#     network1.add(ac)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2  3  4  5  6  7\n",
       "102  0  1  0  0  0  0  0  0\n",
       "37   0  0  0  0  1  0  0  0\n",
       "113  0  0  0  0  0  0  1  0\n",
       "120  0  0  0  1  0  0  0  0\n",
       "143  0  0  1  0  0  0  0  0\n",
       "..  .. .. .. .. .. .. .. ..\n",
       "108  0  1  0  0  0  0  0  0\n",
       "167  0  0  0  0  0  1  0  0\n",
       "0    0  0  0  0  0  1  0  0\n",
       "40   0  0  1  0  0  0  0  0\n",
       "145  0  1  0  0  0  0  0  0\n",
       "\n",
       "[155 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#network1.train(np.expand_dims(X_train.to_numpy(), axis=1), np.expand_dims(y_train.to_numpy(), axis=1), epochs=epochs)\n",
    "network1.fit(X_train, y_train)\n",
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(X_train.to_numpy(), axis=1).shape[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "out = network1.predict(X_train)\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2  3  4  5  6  7\n",
       "102  0  1  0  0  0  0  0  0\n",
       "37   0  0  0  0  1  0  0  0\n",
       "113  0  0  0  0  0  0  1  0\n",
       "120  0  0  0  1  0  0  0  0\n",
       "143  0  0  1  0  0  0  0  0\n",
       "..  .. .. .. .. .. .. .. ..\n",
       "108  0  1  0  0  0  0  0  0\n",
       "167  0  0  0  0  0  1  0  0\n",
       "0    0  0  0  0  0  1  0  0\n",
       "40   0  0  1  0  0  0  0  0\n",
       "145  0  1  0  0  0  0  0  0\n",
       "\n",
       "[155 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 65)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 72: 0.0576915593712906\n",
      "2 / 72: 0.037967692967692965\n",
      "3 / 72: 0.04638456848983165\n",
      "4 / 72: 0.0576915593712906\n",
      "5 / 72: 0.0077178030303030306\n",
      "6 / 72: 0.0077178030303030306\n",
      "7 / 72: 0.0077178030303030306\n",
      "8 / 72: 0.0077178030303030306\n",
      "9 / 72: 0.0077178030303030306\n",
      "10 / 72: 0.0576915593712906\n",
      "11 / 72: 0.03317155067155067\n",
      "12 / 72: 0.04638456848983165\n",
      "13 / 72: 0.0576915593712906\n",
      "14 / 72: 0.0077178030303030306\n",
      "15 / 72: 0.016220238095238097\n",
      "16 / 72: 0.026024384112619404\n",
      "17 / 72: 0.0077178030303030306\n",
      "18 / 72: 0.01879827688651218\n",
      "19 / 72: 0.0576915593712906\n",
      "20 / 72: 0.040233774839038\n",
      "21 / 72: 0.0670439091491723\n",
      "22 / 72: 0.0576915593712906\n",
      "23 / 72: 0.0077178030303030306\n",
      "24 / 72: 0.014386512180629826\n",
      "25 / 72: 0.0077178030303030306\n",
      "26 / 72: 0.0077178030303030306\n",
      "27 / 72: 0.0077178030303030306\n",
      "28 / 72: 0.0576915593712906\n",
      "29 / 72: 0.04266258067454876\n",
      "30 / 72: 0.04638456848983165\n",
      "31 / 72: 0.0576915593712906\n",
      "32 / 72: 0.0077178030303030306\n",
      "33 / 72: 0.03142208485958485\n",
      "34 / 72: 0.020747773790536946\n",
      "35 / 72: 0.0077178030303030306\n",
      "36 / 72: 0.02317511940673705\n",
      "37 / 72: 0.14460986855933664\n",
      "38 / 72: 0.0077178030303030306\n",
      "39 / 72: 0.040115995115995104\n",
      "40 / 72: 0.040233774839038\n",
      "41 / 72: 0.0077178030303030306\n",
      "42 / 72: 0.040115995115995104\n",
      "43 / 72: 0.0077178030303030306\n",
      "44 / 72: 0.0077178030303030306\n",
      "45 / 72: 0.0077178030303030306\n",
      "46 / 72: 0.0576915593712906\n",
      "47 / 72: 0.0077178030303030306\n",
      "48 / 72: 0.040115995115995104\n",
      "49 / 72: 0.037967692967692965\n",
      "50 / 72: 0.0077178030303030306\n",
      "51 / 72: 0.037967692967692965\n",
      "52 / 72: 0.030191926129426127\n",
      "53 / 72: 0.0077178030303030306\n",
      "54 / 72: 0.0074420677361853845\n",
      "55 / 72: 0.10502213462739778\n",
      "56 / 72: 0.00918560606060606\n",
      "57 / 72: 0.0748401924872513\n",
      "58 / 72: 0.3082379426129426\n",
      "59 / 72: 0.0077178030303030306\n",
      "60 / 72: 0.14193542887916288\n",
      "61 / 72: 0.0077178030303030306\n",
      "62 / 72: 0.0077178030303030306\n",
      "63 / 72: 0.0077178030303030306\n",
      "64 / 72: 0.0576915593712906\n",
      "65 / 72: 0.0077178030303030306\n",
      "66 / 72: 0.040115995115995104\n",
      "67 / 72: 0.04638456848983165\n",
      "68 / 72: 0.0077178030303030306\n",
      "69 / 72: 0.037967692967692965\n",
      "70 / 72: 0.0196031746031746\n",
      "71 / 72: 0.0077178030303030306\n",
      "72 / 72: 0.03328933039459355\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>test_score</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>score_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'learning_rate': 0.1, 'epochs': 1000, 'node_c...</td>\n",
       "      <td>[0.06547619047619048, 0.046052631578947366, 0....</td>\n",
       "      <td>[8.432593584060669, 8.294090270996094, 8.32311...</td>\n",
       "      <td>[0.004781961441040039, 0.005013942718505859, 0...</td>\n",
       "      <td>0.057692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 0.1, 'epochs': 1000, 'node_c...</td>\n",
       "      <td>[0.03472222222222222, 0.03472222222222222, 0.0...</td>\n",
       "      <td>[6.82401442527771, 6.7685463428497314, 6.80252...</td>\n",
       "      <td>[0.005001068115234375, 0.004985332489013672, 0...</td>\n",
       "      <td>0.037968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.1, 'epochs': 1000, 'node_c...</td>\n",
       "      <td>[0.06547619047619048, 0.046052631578947366, 0....</td>\n",
       "      <td>[5.839398384094238, 5.901453495025635, 5.82243...</td>\n",
       "      <td>[0.00500178337097168, 0.004001140594482422, 0....</td>\n",
       "      <td>0.046385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'learning_rate': 0.1, 'epochs': 1000, 'node_c...</td>\n",
       "      <td>[0.06547619047619048, 0.046052631578947366, 0....</td>\n",
       "      <td>[8.476042747497559, 8.456154823303223, 8.53028...</td>\n",
       "      <td>[0.00510406494140625, 0.0030159950256347656, 0...</td>\n",
       "      <td>0.057692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 0.1, 'epochs': 1000, 'node_c...</td>\n",
       "      <td>[0.0, 0.0078125, 0.015151515151515152, 0.00781...</td>\n",
       "      <td>[7.537651538848877, 7.088119029998779, 7.32416...</td>\n",
       "      <td>[0.002997875213623047, 0.004002571105957031, 0...</td>\n",
       "      <td>0.007718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>{'learning_rate': 0.5, 'epochs': 2000, 'node_c...</td>\n",
       "      <td>[0.0, 0.0078125, 0.015151515151515152, 0.00781...</td>\n",
       "      <td>[22.491724252700806, 22.554781913757324, 22.71...</td>\n",
       "      <td>[0.004137992858886719, 0.005690097808837891, 0...</td>\n",
       "      <td>0.007718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>{'learning_rate': 0.5, 'epochs': 2000, 'node_c...</td>\n",
       "      <td>[0.03472222222222222, 0.03472222222222222, 0.0...</td>\n",
       "      <td>[19.37912631034851, 19.459699392318726, 19.445...</td>\n",
       "      <td>[0.003675699234008789, 0.0036573410034179688, ...</td>\n",
       "      <td>0.037968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>{'learning_rate': 0.5, 'epochs': 2000, 'node_c...</td>\n",
       "      <td>[0.03472222222222222, 0.03472222222222222, 0.0...</td>\n",
       "      <td>[27.706740856170654, 27.50494933128357, 27.829...</td>\n",
       "      <td>[0.004156351089477539, 0.0036385059356689453, ...</td>\n",
       "      <td>0.019603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>{'learning_rate': 0.5, 'epochs': 2000, 'node_c...</td>\n",
       "      <td>[0.0, 0.0078125, 0.015151515151515152, 0.00781...</td>\n",
       "      <td>[23.927967309951782, 24.109249591827393, 23.80...</td>\n",
       "      <td>[0.005060911178588867, 0.003632783889770508, 0...</td>\n",
       "      <td>0.007718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>{'learning_rate': 0.5, 'epochs': 2000, 'node_c...</td>\n",
       "      <td>[0.028571428571428574, 0.046052631578947366, 0...</td>\n",
       "      <td>[21.284603357315063, 21.382659673690796, 21.63...</td>\n",
       "      <td>[0.0052242279052734375, 0.0036187171936035156,...</td>\n",
       "      <td>0.033289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params   \n",
       "0   {'learning_rate': 0.1, 'epochs': 1000, 'node_c...  \\\n",
       "1   {'learning_rate': 0.1, 'epochs': 1000, 'node_c...   \n",
       "2   {'learning_rate': 0.1, 'epochs': 1000, 'node_c...   \n",
       "3   {'learning_rate': 0.1, 'epochs': 1000, 'node_c...   \n",
       "4   {'learning_rate': 0.1, 'epochs': 1000, 'node_c...   \n",
       "..                                                ...   \n",
       "67  {'learning_rate': 0.5, 'epochs': 2000, 'node_c...   \n",
       "68  {'learning_rate': 0.5, 'epochs': 2000, 'node_c...   \n",
       "69  {'learning_rate': 0.5, 'epochs': 2000, 'node_c...   \n",
       "70  {'learning_rate': 0.5, 'epochs': 2000, 'node_c...   \n",
       "71  {'learning_rate': 0.5, 'epochs': 2000, 'node_c...   \n",
       "\n",
       "                                           test_score   \n",
       "0   [0.06547619047619048, 0.046052631578947366, 0....  \\\n",
       "1   [0.03472222222222222, 0.03472222222222222, 0.0...   \n",
       "2   [0.06547619047619048, 0.046052631578947366, 0....   \n",
       "3   [0.06547619047619048, 0.046052631578947366, 0....   \n",
       "4   [0.0, 0.0078125, 0.015151515151515152, 0.00781...   \n",
       "..                                                ...   \n",
       "67  [0.0, 0.0078125, 0.015151515151515152, 0.00781...   \n",
       "68  [0.03472222222222222, 0.03472222222222222, 0.0...   \n",
       "69  [0.03472222222222222, 0.03472222222222222, 0.0...   \n",
       "70  [0.0, 0.0078125, 0.015151515151515152, 0.00781...   \n",
       "71  [0.028571428571428574, 0.046052631578947366, 0...   \n",
       "\n",
       "                                             fit_time   \n",
       "0   [8.432593584060669, 8.294090270996094, 8.32311...  \\\n",
       "1   [6.82401442527771, 6.7685463428497314, 6.80252...   \n",
       "2   [5.839398384094238, 5.901453495025635, 5.82243...   \n",
       "3   [8.476042747497559, 8.456154823303223, 8.53028...   \n",
       "4   [7.537651538848877, 7.088119029998779, 7.32416...   \n",
       "..                                                ...   \n",
       "67  [22.491724252700806, 22.554781913757324, 22.71...   \n",
       "68  [19.37912631034851, 19.459699392318726, 19.445...   \n",
       "69  [27.706740856170654, 27.50494933128357, 27.829...   \n",
       "70  [23.927967309951782, 24.109249591827393, 23.80...   \n",
       "71  [21.284603357315063, 21.382659673690796, 21.63...   \n",
       "\n",
       "                                           score_time  score_mean  \n",
       "0   [0.004781961441040039, 0.005013942718505859, 0...    0.057692  \n",
       "1   [0.005001068115234375, 0.004985332489013672, 0...    0.037968  \n",
       "2   [0.00500178337097168, 0.004001140594482422, 0....    0.046385  \n",
       "3   [0.00510406494140625, 0.0030159950256347656, 0...    0.057692  \n",
       "4   [0.002997875213623047, 0.004002571105957031, 0...    0.007718  \n",
       "..                                                ...         ...  \n",
       "67  [0.004137992858886719, 0.005690097808837891, 0...    0.007718  \n",
       "68  [0.003675699234008789, 0.0036573410034179688, ...    0.037968  \n",
       "69  [0.004156351089477539, 0.0036385059356689453, ...    0.019603  \n",
       "70  [0.005060911178588867, 0.003632783889770508, 0...    0.007718  \n",
       "71  [0.0052242279052734375, 0.0036187171936035156,...    0.033289  \n",
       "\n",
       "[72 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'learning_rate': [0.1, 0.5],\n",
    "    'epochs': [1000,2000],\n",
    "    'node_counts': [[3,3],[10,10],[100,100],[3,3,3],[10,10,10],[20,20,20]],\n",
    "    'activation_function': [(sigmoid,sigmoid_derivative),(relu,relu_derivative),(tanh,tanh_derivative)],\n",
    "\n",
    "}\n",
    "gs = GridSearcher(network1, parameters, X_train, y_train)\n",
    "gs_results = gs.search()\n",
    "gs_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06547619, 0.04605263, 0.08510638, 0.05128205, 0.04054054])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results[\"test_score\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05769156, 0.03796769, 0.04638457, 0.0077178 , 0.03317155,\n",
       "       0.01622024, 0.02602438, 0.01879828, 0.04023377, 0.06704391,\n",
       "       0.01438651, 0.04266258, 0.03142208, 0.02074777, 0.02317512,\n",
       "       0.14460987, 0.040116  , 0.03019193, 0.00744207, 0.10502213,\n",
       "       0.00918561, 0.07484019, 0.30823794, 0.14193543, 0.01960317,\n",
       "       0.03328933])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results[\"score_mean\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_sklearn = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_sk = {\n",
    "    'learning_rate_init': [0.01, 0.1,0.5,0.8],\n",
    "    \"learning_rate\": [\"constant\"],\n",
    "    'max_iter': [10,100,1000,2000],\n",
    "    'hidden_layer_sizes': [[3,3],[5,5],[10,10],[50,50],[100,100],[3,3,3],[5,5,5],[10,10,10],[20,20,20]],\n",
    "    'activation': [\"logistic\", \"relu\", \"tanh\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_nn = MLPClassifier()\n",
    "\n",
    "gs_sk = GridSearcher(sk_nn, parameters_sk, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 432: 0.05137094681309077\n",
      "2 / 432: 0.12988499121651298\n",
      "3 / 432: 0.04198814576910552\n",
      "4 / 432: 0.025505050505050503\n",
      "5 / 432: 0.09341966742954969\n",
      "6 / 432: 0.10850945115547517\n",
      "7 / 432: 0.0\n",
      "8 / 432: 0.04169244704570792\n",
      "9 / 432: 0.05385302197802198\n",
      "10 / 432: 0.0\n",
      "11 / 432: 0.08295008912655971\n",
      "12 / 432: 0.14532300302037146\n",
      "13 / 432: 0.0\n",
      "14 / 432: 0.2940652257099625\n",
      "15 / 432: 0.3086485193550411\n",
      "16 / 432: 0.032382409257409255\n",
      "17 / 432: 0.11913388255703486\n",
      "18 / 432: 0.05314692031603796\n",
      "19 / 432: 0.06622207767154575\n",
      "20 / 432: 0.09673466602309293\n",
      "21 / 432: 0.043073007909964434\n",
      "22 / 432: 0.01731863442389758\n",
      "23 / 432: 0.049527196940990045\n",
      "24 / 432: 0.0029411764705882353\n",
      "25 / 432: 0.0\n",
      "26 / 432: 0.0\n",
      "27 / 432: 0.01388888888888889\n",
      "28 / 432: 0.0\n",
      "29 / 432: 0.08098647675853557\n",
      "30 / 432: 0.06125541125541124\n",
      "31 / 432: 0.0\n",
      "32 / 432: 0.08268120768120768\n",
      "33 / 432: 0.10125646997929608\n",
      "34 / 432: 0.0\n",
      "35 / 432: 0.28819245569245566\n",
      "36 / 432: 0.32591158841158846\n",
      "37 / 432: 0.3002141145891146\n",
      "38 / 432: 0.38086136086136085\n",
      "39 / 432: 0.35441066286654527\n",
      "40 / 432: 0.31757284382284384\n",
      "41 / 432: 0.38788704759293\n",
      "42 / 432: 0.39346479172951965\n",
      "43 / 432: 0.0\n",
      "44 / 432: 0.1109271978021978\n",
      "45 / 432: 0.03603896103896104\n",
      "46 / 432: 0.0\n",
      "47 / 432: 0.10227770595417654\n",
      "48 / 432: 0.04652777777777778\n",
      "49 / 432: 0.0\n",
      "50 / 432: 0.2596408983173689\n",
      "51 / 432: 0.2195325890584511\n",
      "52 / 432: 0.0\n",
      "53 / 432: 0.38070901320901324\n",
      "54 / 432: 0.3316616855366855\n",
      "55 / 432: 0.05819902319902319\n",
      "56 / 432: 0.20806929401156476\n",
      "57 / 432: 0.22451107307724955\n",
      "58 / 432: 0.31210208447420723\n",
      "59 / 432: 0.2749515688989373\n",
      "60 / 432: 0.37151664511958626\n",
      "61 / 432: 0.337702922077922\n",
      "62 / 432: 0.324134089594616\n",
      "63 / 432: 0.3543840168072904\n",
      "64 / 432: 0.3889842243103113\n",
      "65 / 432: 0.37285207847707846\n",
      "66 / 432: 0.3865490041567628\n",
      "67 / 432: 0.3955420505420505\n",
      "68 / 432: 0.3757861814111814\n",
      "69 / 432: 0.3954385238944062\n",
      "70 / 432: 0.0\n",
      "71 / 432: 0.20989063009573847\n",
      "72 / 432: 0.12437499999999999\n",
      "73 / 432: 0.1130929487179487\n",
      "74 / 432: 0.2607150488400488\n",
      "75 / 432: 0.23619547119547118\n",
      "76 / 432: 0.300709166035253\n",
      "77 / 432: 0.3289057538322244\n",
      "78 / 432: 0.3510321622821623\n",
      "79 / 432: 0.33871117771117765\n",
      "80 / 432: 0.323608327059414\n",
      "81 / 432: 0.33164440135028367\n",
      "82 / 432: 0.1437608225108225\n",
      "83 / 432: 0.21156762510309424\n",
      "84 / 432: 0.29782992719205537\n",
      "85 / 432: 0.26673201798201795\n",
      "86 / 432: 0.2979914710892972\n",
      "87 / 432: 0.3360880418601007\n",
      "88 / 432: 0.3468704906204906\n",
      "89 / 432: 0.344490786990787\n",
      "90 / 432: 0.36021194491782726\n",
      "91 / 432: 0.21019240019240018\n",
      "92 / 432: 0.3750086256336256\n",
      "93 / 432: 0.38537809412809415\n",
      "94 / 432: 0.3756546462796463\n",
      "95 / 432: 0.39148734618843317\n",
      "96 / 432: 0.39815348613523055\n",
      "97 / 432: 0.05229166666666667\n",
      "98 / 432: 0.21563840446992621\n",
      "99 / 432: 0.17077220981632749\n",
      "100 / 432: 0.13059981684981686\n",
      "101 / 432: 0.28947988835032445\n",
      "102 / 432: 0.3051768411327235\n",
      "103 / 432: 0.1901244588744589\n",
      "104 / 432: 0.37057857347331036\n",
      "105 / 432: 0.3245062535503712\n",
      "106 / 432: 0.3791510945306012\n",
      "107 / 432: 0.3333439477189477\n",
      "108 / 432: 0.3612785199549905\n",
      "109 / 432: 0.0\n",
      "110 / 432: 0.06882976672450355\n",
      "111 / 432: 0.0\n",
      "112 / 432: 0.0\n",
      "113 / 432: 0.05847763347763348\n",
      "114 / 432: 0.024350649350649352\n",
      "115 / 432: 0.0\n",
      "116 / 432: 0.05696969696969697\n",
      "117 / 432: 0.13376845376845375\n",
      "118 / 432: 0.0\n",
      "119 / 432: 0.21545596288243346\n",
      "120 / 432: 0.25491002053502054\n",
      "121 / 432: 0.0\n",
      "122 / 432: 0.06804222093695778\n",
      "123 / 432: 0.0543813387423935\n",
      "124 / 432: 0.0\n",
      "125 / 432: 0.017142857142857144\n",
      "126 / 432: 0.0\n",
      "127 / 432: 0.0\n",
      "128 / 432: 0.10822510822510822\n",
      "129 / 432: 0.023333333333333334\n",
      "130 / 432: 0.0\n",
      "131 / 432: 0.144362756808409\n",
      "132 / 432: 0.08905309364548494\n",
      "133 / 432: 0.0\n",
      "134 / 432: 0.09609762218457871\n",
      "135 / 432: 0.08412719633307869\n",
      "136 / 432: 0.06202380952380952\n",
      "137 / 432: 0.11035564925270809\n",
      "138 / 432: 0.07251359751359751\n",
      "139 / 432: 0.08777243589743589\n",
      "140 / 432: 0.22340042150943681\n",
      "141 / 432: 0.24453562087563102\n",
      "142 / 432: 0.2666168091168091\n",
      "143 / 432: 0.329376076821729\n",
      "144 / 432: 0.3146178821178821\n",
      "145 / 432: 0.2048204699210891\n",
      "146 / 432: 0.3496323791151377\n",
      "147 / 432: 0.3800768675768676\n",
      "148 / 432: 0.015384615384615382\n",
      "149 / 432: 0.2458837599598469\n",
      "150 / 432: 0.22834421134421135\n",
      "151 / 432: 0.042802338326635006\n",
      "152 / 432: 0.08224747474747474\n",
      "153 / 432: 0.11691418230891915\n",
      "154 / 432: 0.07076923076923078\n",
      "155 / 432: 0.1580740696501566\n",
      "156 / 432: 0.12563236763236763\n",
      "157 / 432: 0.138603687978688\n",
      "158 / 432: 0.2909376472410154\n",
      "159 / 432: 0.3683082415105742\n",
      "160 / 432: 0.05370115995115995\n",
      "161 / 432: 0.41042117604617606\n",
      "162 / 432: 0.3687111777111777\n",
      "163 / 432: 0.1324263784461153\n",
      "164 / 432: 0.2185057973931813\n",
      "165 / 432: 0.263413775766717\n",
      "166 / 432: 0.34021000928895667\n",
      "167 / 432: 0.28712973064946745\n",
      "168 / 432: 0.20435585248085247\n",
      "169 / 432: 0.3824900140708964\n",
      "170 / 432: 0.35963261738261737\n",
      "171 / 432: 0.3661028092278092\n",
      "172 / 432: 0.3436406573896652\n",
      "173 / 432: 0.3211981999482\n",
      "174 / 432: 0.35878479799068036\n",
      "175 / 432: 0.01875\n",
      "176 / 432: 0.16822586263075695\n",
      "177 / 432: 0.26331238206238206\n",
      "178 / 432: 0.17511946386946384\n",
      "179 / 432: 0.10559159949246158\n",
      "180 / 432: 0.15513857466063347\n",
      "181 / 432: 0.16976703248442376\n",
      "182 / 432: 0.15350595238095238\n",
      "183 / 432: 0.15973417277596844\n",
      "184 / 432: 0.15134293242988894\n",
      "185 / 432: 0.32179038601353177\n",
      "186 / 432: 0.30123188606884255\n",
      "187 / 432: 0.1390151515151515\n",
      "188 / 432: 0.36109682474388355\n",
      "189 / 432: 0.28454710494184177\n",
      "190 / 432: 0.19762192120744754\n",
      "191 / 432: 0.19870447363094423\n",
      "192 / 432: 0.060504201680672276\n",
      "193 / 432: 0.22463023088023087\n",
      "194 / 432: 0.28575641997956575\n",
      "195 / 432: 0.2747580906810116\n",
      "196 / 432: 0.34194294594294594\n",
      "197 / 432: 0.35179562031535716\n",
      "198 / 432: 0.3129396665426077\n",
      "199 / 432: 0.3746134652384653\n",
      "200 / 432: 0.31605236838325074\n",
      "201 / 432: 0.37310424780533474\n",
      "202 / 432: 0.0\n",
      "203 / 432: 0.28586716743046664\n",
      "204 / 432: 0.13321411318150447\n",
      "205 / 432: 0.14940212837271657\n",
      "206 / 432: 0.058195072900955255\n",
      "207 / 432: 0.05166666666666666\n",
      "208 / 432: 0.27817295621475185\n",
      "209 / 432: 0.27757575757575753\n",
      "210 / 432: 0.1595992202242202\n",
      "211 / 432: 0.20677582286134916\n",
      "212 / 432: 0.3082963033698328\n",
      "213 / 432: 0.3527043071870658\n",
      "214 / 432: 0.14481547619047622\n",
      "215 / 432: 0.3657139388389388\n",
      "216 / 432: 0.3903890621905327\n",
      "217 / 432: 0.0\n",
      "218 / 432: 0.011111111111111112\n",
      "219 / 432: 0.026151315789473682\n",
      "220 / 432: 0.0\n",
      "221 / 432: 0.0\n",
      "222 / 432: 0.019805194805194805\n",
      "223 / 432: 0.0\n",
      "224 / 432: 0.018055555555555554\n",
      "225 / 432: 0.02911255411255411\n",
      "226 / 432: 0.03422213129659938\n",
      "227 / 432: 0.007142857142857143\n",
      "228 / 432: 0.009210526315789473\n",
      "229 / 432: 0.04430276140802457\n",
      "230 / 432: 0.015250965250965249\n",
      "231 / 432: 0.03063887093298858\n",
      "232 / 432: 0.0\n",
      "233 / 432: 0.0\n",
      "234 / 432: 0.015\n",
      "235 / 432: 0.0\n",
      "236 / 432: 0.00909090909090909\n",
      "237 / 432: 0.011538461538461537\n",
      "238 / 432: 0.0\n",
      "239 / 432: 0.014705882352941175\n",
      "240 / 432: 0.017948717948717947\n",
      "241 / 432: 0.0\n",
      "242 / 432: 0.0\n",
      "243 / 432: 0.012658730158730157\n",
      "244 / 432: 0.02720588235294118\n",
      "245 / 432: 0.0125\n",
      "246 / 432: 0.04643665158371041\n",
      "247 / 432: 0.09978697228697228\n",
      "248 / 432: 0.0\n",
      "249 / 432: 0.0314935064935065\n",
      "250 / 432: 0.0\n",
      "251 / 432: 0.03798076923076923\n",
      "252 / 432: 0.040737713849842\n",
      "253 / 432: 0.013095238095238096\n",
      "254 / 432: 0.0\n",
      "255 / 432: 0.01731863442389758\n",
      "256 / 432: 0.05375433520380328\n",
      "257 / 432: 0.0\n",
      "258 / 432: 0.030708874458874456\n",
      "259 / 432: 0.0\n",
      "260 / 432: 0.0\n",
      "261 / 432: 0.00909090909090909\n",
      "262 / 432: 0.01388888888888889\n",
      "263 / 432: 0.0\n",
      "264 / 432: 0.0\n",
      "265 / 432: 0.0\n",
      "266 / 432: 0.0\n",
      "267 / 432: 0.0\n",
      "268 / 432: 0.0\n",
      "269 / 432: 0.0\n",
      "270 / 432: 0.015052552552552551\n",
      "271 / 432: 0.054074712643678156\n",
      "272 / 432: 0.02\n",
      "273 / 432: 0.020000000000000004\n",
      "274 / 432: 0.07166491596638655\n",
      "275 / 432: 0.012045454545454545\n",
      "276 / 432: 0.03785714285714285\n",
      "277 / 432: 0.1351008991008991\n",
      "278 / 432: 0.0\n",
      "279 / 432: 0.05512566137566137\n",
      "280 / 432: 0.027575044680307838\n",
      "281 / 432: 0.007142857142857143\n",
      "282 / 432: 0.03962439883492515\n",
      "283 / 432: 0.04608721066167874\n",
      "284 / 432: 0.0\n",
      "285 / 432: 0.013286713286713287\n",
      "286 / 432: 0.008695652173913044\n",
      "287 / 432: 0.020967741935483872\n",
      "288 / 432: 0.005555555555555555\n",
      "289 / 432: 0.010869565217391304\n",
      "290 / 432: 0.0\n",
      "291 / 432: 0.0\n",
      "292 / 432: 0.010869565217391304\n",
      "293 / 432: 0.0\n",
      "294 / 432: 0.0\n",
      "295 / 432: 0.0\n",
      "296 / 432: 0.007142857142857143\n",
      "297 / 432: 0.015714285714285715\n",
      "298 / 432: 0.0\n",
      "299 / 432: 0.05245192307692308\n",
      "300 / 432: 0.016666666666666666\n",
      "301 / 432: 0.017741935483870964\n",
      "302 / 432: 0.08277504105090312\n",
      "303 / 432: 0.05830555555555557\n",
      "304 / 432: 0.10883101375748434\n",
      "305 / 432: 0.01923076923076923\n",
      "306 / 432: 0.032539682539682535\n",
      "307 / 432: 0.0\n",
      "308 / 432: 0.0\n",
      "309 / 432: 0.055482011767006165\n",
      "310 / 432: 0.02691763191763192\n",
      "311 / 432: 0.0\n",
      "312 / 432: 0.04682558580584896\n",
      "313 / 432: 0.0171875\n",
      "314 / 432: 0.0\n",
      "315 / 432: 0.01130952380952381\n",
      "316 / 432: 0.0\n",
      "317 / 432: 0.0\n",
      "318 / 432: 0.0\n",
      "319 / 432: 0.0\n",
      "320 / 432: 0.0\n",
      "321 / 432: 0.013095238095238096\n",
      "322 / 432: 0.0\n",
      "323 / 432: 0.0\n",
      "324 / 432: 0.0\n",
      "325 / 432: 0.0\n",
      "326 / 432: 0.0\n",
      "327 / 432: 0.01702127659574468\n",
      "328 / 432: 0.0\n",
      "329 / 432: 0.0\n",
      "330 / 432: 0.01764705882352941\n",
      "331 / 432: 0.0\n",
      "332 / 432: 0.0\n",
      "333 / 432: 0.015052552552552551\n",
      "334 / 432: 0.01946693657219973\n",
      "335 / 432: 0.0\n",
      "336 / 432: 0.0606439577492209\n",
      "337 / 432: 0.04918766408704489\n",
      "338 / 432: 0.0\n",
      "339 / 432: 0.06429351444154076\n",
      "340 / 432: 0.0\n",
      "341 / 432: 0.0\n",
      "342 / 432: 0.01346153846153846\n",
      "343 / 432: 0.0\n",
      "344 / 432: 0.0\n",
      "345 / 432: 0.0\n",
      "346 / 432: 0.0\n",
      "347 / 432: 0.0\n",
      "348 / 432: 0.04249985671038302\n",
      "349 / 432: 0.026472626472626472\n",
      "350 / 432: 0.01702127659574468\n",
      "351 / 432: 0.05738279195726004\n",
      "352 / 432: 0.018749999999999996\n",
      "353 / 432: 0.005555555555555555\n",
      "354 / 432: 0.01\n",
      "355 / 432: 0.0\n",
      "356 / 432: 0.0\n",
      "357 / 432: 0.029122807017543863\n",
      "358 / 432: 0.0\n",
      "359 / 432: 0.0\n",
      "360 / 432: 0.0090625\n",
      "361 / 432: 0.032562174667437827\n",
      "362 / 432: 0.018333333333333333\n",
      "363 / 432: 0.023351648351648352\n",
      "364 / 432: 0.03590241101964226\n",
      "365 / 432: 0.0\n",
      "366 / 432: 0.0506450302502934\n",
      "367 / 432: 0.0\n",
      "368 / 432: 0.0\n",
      "369 / 432: 0.024747474747474747\n",
      "370 / 432: 0.0\n",
      "371 / 432: 0.0\n",
      "372 / 432: 0.0\n",
      "373 / 432: 0.0\n",
      "374 / 432: 0.0\n",
      "375 / 432: 0.0\n",
      "376 / 432: 0.0\n",
      "377 / 432: 0.01702127659574468\n",
      "378 / 432: 0.029502929502929504\n",
      "379 / 432: 0.0\n",
      "380 / 432: 0.0\n",
      "381 / 432: 0.01875\n",
      "382 / 432: 0.013636363636363636\n",
      "383 / 432: 0.0125\n",
      "384 / 432: 0.029210526315789475\n",
      "385 / 432: 0.0\n",
      "386 / 432: 0.0\n",
      "387 / 432: 0.019210526315789473\n",
      "388 / 432: 0.03145975645975646\n",
      "389 / 432: 0.015476190476190477\n",
      "390 / 432: 0.02647664835164835\n",
      "391 / 432: 0.018364518364518363\n",
      "392 / 432: 0.01\n",
      "393 / 432: 0.04373001544054176\n",
      "394 / 432: 0.0125\n",
      "395 / 432: 0.0\n",
      "396 / 432: 0.0\n",
      "397 / 432: 0.0\n",
      "398 / 432: 0.0\n",
      "399 / 432: 0.0\n",
      "400 / 432: 0.0\n",
      "401 / 432: 0.0\n",
      "402 / 432: 0.011111111111111112\n",
      "403 / 432: 0.0\n",
      "404 / 432: 0.0\n",
      "405 / 432: 0.026381951381951384\n",
      "406 / 432: 0.018965517241379314\n",
      "407 / 432: 0.0\n",
      "408 / 432: 0.0125\n",
      "409 / 432: 0.0\n",
      "410 / 432: 0.0\n",
      "411 / 432: 0.0\n",
      "412 / 432: 0.0\n",
      "413 / 432: 0.007142857142857143\n",
      "414 / 432: 0.015\n",
      "415 / 432: 0.02814779064779065\n",
      "416 / 432: 0.011805555555555555\n",
      "417 / 432: 0.0\n",
      "418 / 432: 0.015052552552552551\n",
      "419 / 432: 0.0\n",
      "420 / 432: 0.047502063044826195\n",
      "421 / 432: 0.016666666666666666\n",
      "422 / 432: 0.0\n",
      "423 / 432: 0.02\n",
      "424 / 432: 0.0\n",
      "425 / 432: 0.008108108108108107\n",
      "426 / 432: 0.03845208845208845\n",
      "427 / 432: 0.0\n",
      "428 / 432: 0.0\n",
      "429 / 432: 0.008108108108108107\n",
      "430 / 432: 0.0\n",
      "431 / 432: 0.0\n",
      "432 / 432: 0.02037202380952381\n"
     ]
    }
   ],
   "source": [
    "gs_results_sk = gs_sk.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.5, 'epochs': 2000, 'node_counts': [10, 10], 'activation_function': (<function sigmoid at 0x0000022BA3580720>, <function sigmoid_derivative at 0x0000022BA35807C0>)}\n",
      "0.3082379426129426\n"
     ]
    }
   ],
   "source": [
    "self_max = gs_results[\"score_mean\"].idxmax()\n",
    "print(gs_results.loc[self_max][\"params\"])\n",
    "print(gs_results.loc[self_max][\"score_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.80      0.80      0.80        10\n",
      "           2       0.50      0.17      0.25         6\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.33      0.50      0.40         2\n",
      "           5       0.38      0.60      0.46         5\n",
      "           6       0.56      0.75      0.64        12\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.56      0.56      0.56        39\n",
      "   macro avg       0.32      0.35      0.32        39\n",
      "weighted avg       0.52      0.56      0.52        39\n",
      " samples avg       0.56      0.56      0.56        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vali\\Documents\\GitHub\\Studium\\ml\\ML_SS_23\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\vali\\Documents\\GitHub\\Studium\\ml\\ML_SS_23\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "network1.set_params(**gs_results.loc[self_max][\"params\"])\n",
    "network1.fit(X_train, y_train)\n",
    "test_pred = network1.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.80      0.80      0.80        10\n",
      "           2       0.50      0.17      0.25         6\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.33      0.50      0.40         2\n",
      "           5       0.38      0.60      0.46         5\n",
      "           6       0.56      0.75      0.64        12\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.56      0.56      0.56        39\n",
      "   macro avg       0.32      0.35      0.32        39\n",
      "weighted avg       0.52      0.56      0.52        39\n",
      " samples avg       0.56      0.56      0.56        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vali\\Documents\\GitHub\\Studium\\ml\\ML_SS_23\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\vali\\Documents\\GitHub\\Studium\\ml\\ML_SS_23\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate_init': 0.1, 'learning_rate': 'constant', 'max_iter': 100, 'hidden_layer_sizes': [20, 20, 20], 'activation': 'relu'}\n",
      "0.41042117604617606\n"
     ]
    }
   ],
   "source": [
    "sk_max = gs_results_sk[\"score_mean\"].idxmax()\n",
    "print(gs_results_sk.loc[sk_max][\"params\"])\n",
    "print(gs_results_sk.loc[sk_max][\"score_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_nn.set_params(**gs_results_sk.loc[sk_max][\"params\"])\n",
    "network1.fit(X_train, y_train)\n",
    "test_pred_sk = network1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.75      0.30      0.43        10\n",
      "           2       0.12      0.17      0.14         6\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.20      0.20      0.20         5\n",
      "           6       0.56      0.83      0.67        12\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.38      0.38      0.38        39\n",
      "   macro avg       0.20      0.19      0.18        39\n",
      "weighted avg       0.41      0.38      0.36        39\n",
      " samples avg       0.38      0.38      0.38        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vali\\Documents\\GitHub\\Studium\\ml\\ML_SS_23\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\vali\\Documents\\GitHub\\Studium\\ml\\ML_SS_23\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_pred_sk))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37c7361227dc3e7733ba0d9221653a542190e1fc763a7f303852558240223e6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
