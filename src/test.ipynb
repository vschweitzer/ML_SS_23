{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from FCLayer import FcLayer\n",
    "from ACLayer import AcLayer\n",
    "from Network import Network\n",
    "from activation_functions import sigmoid, relu, sigmoid_prime, tanh, tanh_prime,relu_prime\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx_train = np.expand_dims(X_train.to_numpy(), axis=1)\\ny_train = np.expand_dims(y_train.to_numpy(), axis=1)\\nx_test = np.expand_dims(X_test.to_numpy(), axis=1)\\ny_test = np.expand_dims(y_test.to_numpy(), axis=1)\\n'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train = np.array([[[0, 0]], [[0, 1]], [[1, 0]], [[1, 1]]])\n",
    "# # x_train = np.array([[[10000, 1111]], [[111110, 5000]], [[100, 220]]])\n",
    "# # y_train = np.array([[[0]], [[1]], [[1]], [[0]]])\n",
    "# y_train = np.array([[[0]], [[1]], [[1]], [[0]]])\n",
    "'''\n",
    "df_vote = pd.read_csv(\"CongressionalVotingID.shuf.lrn.csv\", index_col=\"ID\")\n",
    "df_vote = df_vote.applymap(lambda x: 1 if x == \"y\" else 0 if x == \"n\" else x)\n",
    "df_vote = df_vote.replace(\"democrat\", 1)\n",
    "df_vote = df_vote.replace(\"republican\", 0)\n",
    "df_vote = df_vote.replace(\"unknown\", 0)\n",
    "df_vote.head()\n",
    "\n",
    "df_vote.shape\n",
    "\n",
    "y_train = df_vote.iloc[:, 0]\n",
    "X_train = df_vote.iloc[:, 1:]\n",
    "X_train.shape\n",
    "y_test = pd.read_csv(\"CongressionalVotingID.shuf.sol.ex.csv\", index_col=\"ID\")\n",
    "y_test = y_test.replace(\"democrat\", 1)\n",
    "y_test = y_test.replace(\"republican\", 0)\n",
    "y_test\n",
    "# Create x_val\n",
    "df_test = pd.read_csv(\"CongressionalVotingID.shuf.tes.csv\")\n",
    "df_test = df_test.applymap(lambda x: 1 if x == \"y\" else 0 if x == \"n\" else x)\n",
    "df_test = df_test.replace(\"unknown\", 0)\n",
    "X_test = df_test.iloc[:, 1:]\n",
    "X_test\n",
    "'''\n",
    "\n",
    "# x_train = np.array([[[0, 0]], [[0, 1]], [[1, 0]], [[1, 1]]])\n",
    "# x_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "# y_train = np.array([[[0]], [[1]], [[1]], [[0]]])\n",
    "\n",
    "'''\n",
    "x_train = np.expand_dims(X_train.to_numpy(), axis=1)\n",
    "y_train = np.expand_dims(y_train.to_numpy(), axis=1)\n",
    "x_test = np.expand_dims(X_test.to_numpy(), axis=1)\n",
    "y_test = np.expand_dims(y_test.to_numpy(), axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "df_vote = pd.read_csv(\"CongressionalVotingID.shuf.lrn.csv\", index_col=\"ID\")\n",
    "df_vote = df_vote.applymap(lambda x: 1 if x == \"y\" else 0 if x == \"n\" else x)\n",
    "df_vote = df_vote.replace(\"democrat\", 1)\n",
    "df_vote = df_vote.replace(\"republican\", 0)\n",
    "df_vote = df_vote.replace(\"unknown\", 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_vote.iloc[:,1:], df_vote.iloc[:, 0],test_size=0.4, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train.to_numpy(), axis=1)\n",
    "y_train = np.expand_dims(y_train.to_numpy(), axis=1)\n",
    "x_test = np.expand_dims(x_test.to_numpy(), axis=1)\n",
    "y_test = np.expand_dims(y_test.to_numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict function works\n",
      "[array([[0.99859773]]), array([[0.00088103]]), array([[0.99860138]]), array([[0.99860308]]), array([[0.99686684]]), array([[0.00085926]]), array([[0.99859923]]), array([[0.99859925]]), array([[0.99859908]]), array([[-0.00288051]]), array([[0.00093866]]), array([[0.00099955]]), array([[0.99859063]]), array([[0.99860288]]), array([[0.99858662]]), array([[0.00100804]]), array([[0.99858215]]), array([[0.00099955]]), array([[0.99859783]]), array([[-0.00031842]]), array([[-0.00092704]]), array([[0.00103764]]), array([[0.99854944]]), array([[0.99859763]]), array([[0.99522904]]), array([[0.00100804]]), array([[0.00061491]]), array([[0.99860163]]), array([[0.99860342]]), array([[0.00088103]]), array([[0.9986025]]), array([[0.00198315]]), array([[0.99860145]]), array([[0.99854816]]), array([[0.99860293]]), array([[0.99622269]]), array([[0.99860328]]), array([[0.99849602]]), array([[0.99860334]]), array([[0.00012857]]), array([[0.99859923]]), array([[-0.00240492]]), array([[0.99859613]]), array([[0.99673091]]), array([[0.00059064]]), array([[0.00093866]]), array([[0.99811223]]), array([[0.00321956]]), array([[0.99858662]]), array([[0.00082685]]), array([[0.99858215]]), array([[0.00100189]]), array([[0.99860255]]), array([[0.99860151]]), array([[0.9985761]]), array([[0.99860328]]), array([[0.99858215]]), array([[0.99701301]]), array([[0.99860338]]), array([[0.99859923]]), array([[0.99732409]]), array([[-0.00110698]]), array([[-0.00021372]]), array([[-0.00493905]]), array([[0.99858391]]), array([[0.99859907]]), array([[0.00075886]]), array([[0.99859386]]), array([[0.99860042]]), array([[0.99858275]]), array([[0.99859698]]), array([[0.99860363]]), array([[0.99860025]]), array([[0.99483614]]), array([[0.00095814]]), array([[0.00074072]]), array([[0.00088103]]), array([[0.99478682]]), array([[0.99860277]]), array([[0.99860089]]), array([[0.99821491]]), array([[0.99852051]]), array([[0.99859792]]), array([[-0.00110698]]), array([[0.99860338]]), array([[0.99860172]]), array([[0.99854816]]), array([[0.9986035]]), array([[0.99724402]]), array([[0.00095352]]), array([[0.99860143]]), array([[0.99860343]]), array([[0.99860244]]), array([[0.99859984]]), array([[0.99860258]]), array([[0.99417237]]), array([[0.99860325]]), array([[0.99858215]]), array([[0.99858215]]), array([[0.99860054]]), array([[0.99859908]]), array([[0.99859907]]), array([[0.99858215]]), array([[0.00093009]]), array([[0.99860258]]), array([[0.99860286]]), array([[0.99811223]]), array([[-0.00253906]]), array([[0.99859989]]), array([[0.00100804]]), array([[0.99856132]]), array([[0.99858215]]), array([[0.99860258]]), array([[0.00094137]]), array([[0.00175273]]), array([[0.99860356]]), array([[0.00095814]]), array([[0.99860288]]), array([[0.99859923]]), array([[0.99860221]]), array([[0.00099955]]), array([[0.00012174]]), array([[0.00246501]]), array([[0.0031042]]), array([[0.00095814]]), array([[-0.00493905]]), array([[0.0001662]]), array([[0.00022046]]), array([[0.99860275]]), array([[0.99860059]])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "\n",
    "network1 = Network(learning_rate)\n",
    "\n",
    "# fc1 = FcLayer(2, 3)\n",
    "# ac1 = AcLayer(tanh, tanh_prime)\n",
    "# fc2 = FcLayer(3, 1)\n",
    "# ac2 = AcLayer(tanh, tanh_prime)\n",
    "# network1.add(fc1)\n",
    "# network1.add(ac1)\n",
    "# network1.add(fc2)\n",
    "# network1.add(ac2)\n",
    "\n",
    "input_values = 16\n",
    "output_values = 1\n",
    "intermediate_values = 3\n",
    "layers = 3\n",
    "epochs = 1000\n",
    "\n",
    "for j in range(layers):\n",
    "    i = intermediate_values\n",
    "    o = intermediate_values\n",
    "\n",
    "    if not j:\n",
    "        i = input_values\n",
    "    elif j + 1 == layers:\n",
    "        o = output_values\n",
    "\n",
    "    fc = FcLayer(i, o)\n",
    "    ac = AcLayer(tanh, tanh_prime)\n",
    "    network1.add(fc)\n",
    "    network1.add(ac)\n",
    "\n",
    "network1.train(x_train, y_train, epochs=epochs)\n",
    "\n",
    "out = network1.predict(x_train)\n",
    "#print(out)\n",
    "\n",
    "\n",
    "# fc1.forward_propagation(input)\n",
    "# fc2.forward_propagation(fc1.output)\n",
    "# print(fc2.output)\n",
    "\n",
    "# x_train = np.array([[[0,0]], [[0,1]], [[1,0]], [[1,1]]])\n",
    "# y_train = np.array([[[0]], [[1]], [[1]], [[0]]])\n",
    "\n",
    "# # network\n",
    "# net = Network()\n",
    "# net.add(FCLayer(2, 3))\n",
    "# net.add(ActivationLayer(tanh, tanh_prime))\n",
    "# net.add(FCLayer(3, 1))\n",
    "# net.add(ActivationLayer(tanh, tanh_prime))\n",
    "\n",
    "\n",
    "# train\n",
    "# net.use(mse, mse_prime)\n",
    "# net.fit(x_train, y_train, epochs=1000, learning_rate=0.1)\n",
    "\n",
    "# # test\n",
    "# out = net.predict(x_train)\n",
    "# print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict function works\n",
      "[array([[-0.00343621]]), array([[0.00095814]]), array([[0.99821491]]), array([[0.00092663]]), array([[0.99859933]]), array([[0.00088103]]), array([[-0.00587643]]), array([[0.00091049]]), array([[0.99860172]]), array([[0.00095814]]), array([[0.99856898]]), array([[-0.0047495]]), array([[-0.00110698]]), array([[0.05871406]]), array([[0.99860306]]), array([[0.00103799]]), array([[0.00103815]]), array([[0.99860076]]), array([[0.99860336]]), array([[0.99857781]]), array([[0.99859607]]), array([[0.99860297]]), array([[0.0250302]]), array([[0.00095814]]), array([[0.99859607]]), array([[0.89179223]]), array([[0.99858215]]), array([[0.00100189]]), array([[0.99860303]]), array([[-0.06451908]]), array([[0.97143108]]), array([[0.99858215]]), array([[-0.00273613]]), array([[0.00103257]]), array([[0.99860293]]), array([[0.99859908]]), array([[0.0010361]]), array([[0.99859956]]), array([[0.99860277]]), array([[0.99859907]]), array([[0.00082206]]), array([[0.00103799]]), array([[0.99860193]]), array([[0.99860225]]), array([[0.03768222]]), array([[-0.00110698]]), array([[0.99859651]]), array([[0.0193209]]), array([[0.00100804]]), array([[0.00100804]]), array([[0.00088103]]), array([[0.00750481]]), array([[0.99860212]]), array([[0.99860302]]), array([[0.99858283]]), array([[0.00100189]]), array([[0.01685898]]), array([[0.99671969]]), array([[0.99859386]]), array([[0.99860321]]), array([[0.99860258]]), array([[-0.00343621]]), array([[0.99859923]]), array([[0.99860184]]), array([[0.00026002]]), array([[0.20784789]]), array([[0.00099955]]), array([[0.00084626]]), array([[0.99821491]]), array([[0.00096516]]), array([[0.99843437]]), array([[0.99854816]]), array([[0.99860076]]), array([[0.99859907]]), array([[-0.00545516]]), array([[0.99860369]]), array([[0.00072089]]), array([[0.99858215]]), array([[0.9986006]]), array([[0.00095814]]), array([[0.99860095]]), array([[0.99860356]]), array([[0.00095502]]), array([[0.99578012]]), array([[0.99860218]]), array([[0.99860289]]), array([[0.99860212]]), array([[0.99860309]])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=network1.predict(x_test)\n",
    "y_pred=np.where(np.array(y_pred) > 0.5, 1, 0)\n",
    "np.unique(y_pred)\n",
    "#y_test==y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Classification report for Self Neural Network***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        37\n",
      "           1       1.00      0.94      0.97        51\n",
      "\n",
      "    accuracy                           0.97        88\n",
      "   macro avg       0.96      0.97      0.97        88\n",
      "weighted avg       0.97      0.97      0.97        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=np.squeeze(y_pred),y_true=np.squeeze(y_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tensor Flow***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train,y_train, num_nodes, dropout_prob,lr, batch_size, epochs):\n",
    "    nn_model=tf.keras.Sequential([tf.keras.layers.Dense(num_nodes, activation='relu', input_shape=(16,)),\n",
    "                              tf.keras.layers.Dropout(dropout_prob),\n",
    "                             tf.keras.layers.Dense(num_nodes, activation='relu'),\n",
    "                             tf.keras.layers.Dropout(dropout_prob),\n",
    "                             tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "    nn_model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "    #x_train=x_train.astype(float)\n",
    "\n",
    "    history = nn_model.fit(x_train,y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
    "    return nn_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model, history= train_model(np.squeeze(x_train),np.squeeze(y_train),16 , 0,0.1, 32, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 914us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96        38\n",
      "           1       0.96      0.98      0.97        50\n",
      "\n",
      "    accuracy                           0.97        88\n",
      "   macro avg       0.97      0.96      0.97        88\n",
      "weighted avg       0.97      0.97      0.97        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=nn_model.predict(np.squeeze(x_test))\n",
    "y_pred=(y_pred>0.5).astype(int).reshape(-1)\n",
    "y_pred\n",
    "\n",
    "\n",
    "print(classification_report(y_pred,np.squeeze(y_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Spam Data Self Neural Network***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  spam  \n",
       "0                       278     1  \n",
       "1                      1028     1  \n",
       "2                      2259     1  \n",
       "3                       191     1  \n",
       "4                       191     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data=pd.read_csv('spam_final_df.data')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1], data.iloc[:, -1], test_size=0.2, random_state=26)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.expand_dims(X_test,axis=1)\n",
    "X_train=np.expand_dims(X_train,axis=1)\n",
    "y_train=np.expand_dims(y_train,axis=1)\n",
    "y_test=np.expand_dims(y_test,axis=1)\n",
    "network1 = Network(learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = FcLayer(57,50)\n",
    "ac1 = AcLayer(relu, relu_prime)\n",
    "fc2 = FcLayer(50, 40)\n",
    "ac2 = AcLayer(relu, relu_prime)\n",
    "fc3 = FcLayer(40, 10)\n",
    "ac3 = AcLayer(relu, relu_prime)\n",
    "fc4 = FcLayer(30, 20)\n",
    "ac4 = AcLayer(relu, relu_prime)\n",
    "fc5 = FcLayer(20, 10)\n",
    "ac5 = AcLayer(sigmoid, sigmoid_prime)\n",
    "fc10 = FcLayer(10, 1)\n",
    "ac10= AcLayer(relu, relu_prime)\n",
    "network1.add(fc1)\n",
    "network1.add(ac1)\n",
    "network1.add(fc2)\n",
    "network1.add(ac2)\n",
    "\n",
    "network1.add(fc3)\n",
    "network1.add(ac3)\n",
    "# network1.add(fc4)\n",
    "# network1.add(ac4)\n",
    "# network1.add(fc5)\n",
    "# network1.add(ac5)\n",
    "\n",
    "# network1.add(fc6)\n",
    "# network1.add(ac6)\n",
    "# network1.add(fc7)\n",
    "# network1.add(ac7)\n",
    "# network1.add(fc8)\n",
    "# network1.add(ac8)\n",
    "\n",
    "# network1.add(fc9)\n",
    "# network1.add(ac9)\n",
    "network1.add(fc10)\n",
    "network1.add(ac10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,1) and (57,50) not aligned: 1 (dim 1) != 57 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[300], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m\n\u001b[0;32m----> 2\u001b[0m network1\u001b[39m.\u001b[39;49mtrain(X_train, y_train, epochs\u001b[39m=\u001b[39;49mepochs)\n\u001b[1;32m      4\u001b[0m y_pred \u001b[39m=\u001b[39m network1\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39my_pred unique\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ml/ML_SS_23/src/Network.py:45\u001b[0m, in \u001b[0;36mNetwork.train\u001b[0;34m(self, x_train, y_train, epochs)\u001b[0m\n\u001b[1;32m     43\u001b[0m output \u001b[39m=\u001b[39m x_train[j]\n\u001b[1;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 45\u001b[0m     output \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mforward_propagation(output)\n\u001b[1;32m     46\u001b[0m \u001b[39m# result.append(output)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39m# err = np.mean(np.power(y_train[j] - output, 2))\u001b[39;00m\n\u001b[1;32m     48\u001b[0m error \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m (output \u001b[39m-\u001b[39m y_train[j]) \u001b[39m/\u001b[39m y_train[j]\u001b[39m.\u001b[39msize\n",
      "File \u001b[0;32m~/Documents/ml/ML_SS_23/src/FCLayer.py:15\u001b[0m, in \u001b[0;36mFcLayer.forward_propagation\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_propagation\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m     14\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m---> 15\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias  \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights)\n\u001b[1;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1,1) and (57,50) not aligned: 1 (dim 1) != 57 (dim 0)"
     ]
    }
   ],
   "source": [
    "epochs=1000\n",
    "network1.train(X_train, y_train, epochs=epochs)\n",
    "\n",
    "y_pred = network1.predict(X_test)\n",
    "print(\"y_pred unique\")\n",
    "print(np.unique(y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
